{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 一、PyTorch环境检查"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0+cu101\n",
      "cuda: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "print(\"cuda:\", torch.cuda.is_available())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 二、查看张量类型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "torch.LongTensor\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randn(2, 3)\n",
    "b = torch.randint(0, 1, (2, 3))\n",
    "print(a.type())\n",
    "print(b.type())\n",
    "print(type(a))\n",
    "print(type(b))\n",
    "print(isinstance(a, torch.FloatTensor))\n",
    "print(isinstance(b, torch.FloatTensor))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 三、查看张量尺寸"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) <class 'torch.Size'>\n",
      "torch.Size([2, 3]) <class 'torch.Size'>\n",
      "维度数: 2\n",
      "所占内存大小: 6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randn(2, 3)\n",
    "print(a.size(), type(a.size()))\n",
    "print(a.shape, type(a.shape))\n",
    "print(\"维度数:\", a.dim())\n",
    "print(\"所占内存大小:\", a.numel())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 四、创建张量"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.1 生成值全为1的张量"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.ones(2, 3)\n",
    "print(a)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.2 生成值全为0的张量"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.zeros(2, 3)\n",
    "print(a)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.3 生成值全为指定值的张量"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.6000, 6.6000, 6.6000],\n",
      "        [6.6000, 6.6000, 6.6000]])\n",
      "torch.Size([2, 3])\n",
      "tensor(6.6000)\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.full([2, 3], 6.6)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "\n",
    "a = torch.full([], 6.6)\n",
    "print(a)\n",
    "print(a.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.4 通过list创建张量"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.LongTensor([[1, 2], [3, 4]]))\n",
    "print(torch.Tensor([[1, 2], [3, 4]]))\n",
    "print(torch.FloatTensor([[1, 2], [3, 4]]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.5 通过 ndarray 创建张量"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "tensor([2.0000, 3.3000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "a = np.array([2, 3.3])\n",
    "print(type(a))\n",
    "\n",
    "print(torch.from_numpy(a))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.6 创建指定范围和间距的有序张量"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.arange(0,10): tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "torch.arange(0,10,2): tensor([0, 2, 4, 6, 8])\n",
      "torch.linspace(0,10,steps = 4): tensor([ 0.0000,  3.3333,  6.6667, 10.0000])\n",
      "torch.linspace(0,10,steps = 10): tensor([ 0.0000,  1.1111,  2.2222,  3.3333,  4.4444,  5.5556,  6.6667,  7.7778,\n",
      "         8.8889, 10.0000])\n",
      "torch.linspace(0,10,steps = 11): tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n",
      "torch.logspace(0,-1,steps = 10): tensor([1.0000, 0.7743, 0.5995, 0.4642, 0.3594, 0.2783, 0.2154, 0.1668, 0.1292,\n",
      "        0.1000])\n",
      "torch.logspace(0,1,steps = 10): tensor([ 1.0000,  1.2915,  1.6681,  2.1544,  2.7826,  3.5938,  4.6416,  5.9948,\n",
      "         7.7426, 10.0000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"torch.arange(0,10):\", torch.arange(0, 10))\n",
    "print(\"torch.arange(0,10,2):\", torch.arange(0, 10, 2))\n",
    "print(\"torch.linspace(0,10,steps = 4):\", torch.linspace(0, 10, steps=4))\n",
    "print(\"torch.linspace(0,10,steps = 10):\", torch.linspace(0, 10, steps=10))\n",
    "print(\"torch.linspace(0,10,steps = 11):\", torch.linspace(0, 10, steps=11))\n",
    "print(\"torch.logspace(0,-1,steps = 10):\", torch.logspace(0, -1, steps=10))\n",
    "print(\"torch.logspace(0,1,steps = 10):\", torch.logspace(0, 1, steps=10))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.7 创建单位矩阵（对角线为1）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# n * n\n",
    "print(torch.eye(3))\n",
    "print(torch.eye(4, 4))\n",
    "\n",
    "# 非 n * n\n",
    "print(torch.eye(2, 3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 五、生成随机张量"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.1 按均匀分布生成"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4632, 0.2396],\n",
      "         [0.0917, 0.9208],\n",
      "         [0.0559, 0.2765]],\n",
      "\n",
      "        [[0.7071, 0.8135],\n",
      "         [0.4985, 0.3682],\n",
      "         [0.2049, 0.1780]]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([2, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 生成shape为(2,3,2)的Tensor\n",
    "random_tensor = torch.rand(2, 3, 2)\n",
    "print(random_tensor)\n",
    "print(type(random_tensor))\n",
    "print(random_tensor.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.2 按标准正态分布生成"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.6808, -0.0704],\n",
      "         [ 1.4618, -1.2485],\n",
      "         [ 0.4092,  0.7897]],\n",
      "\n",
      "        [[ 1.2597, -0.1547],\n",
      "         [ 0.1840,  0.3599],\n",
      "         [ 0.4327,  0.1597]]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([2, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 生成shape为(2,3,2)的Tensor\n",
    "random_tensor = torch.randn(2, 3, 2)\n",
    "print(random_tensor)\n",
    "print(type(random_tensor))\n",
    "print(random_tensor.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.3 生成指定区间的整型随机张量"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[3, 1],\n",
      "         [1, 3],\n",
      "         [3, 1]],\n",
      "\n",
      "        [[3, 2],\n",
      "         [3, 3],\n",
      "         [1, 1]]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([2, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 生成shape为(2,3,2)的Tensor\n",
    "# 整数范围[1,4)\n",
    "random_tensor = torch.randint(1, 4, (2, 3, 2))\n",
    "print(random_tensor)\n",
    "print(type(random_tensor))\n",
    "print(random_tensor.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.4 获取随机序列"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 4.5916e-41],\n",
      "        [1.6411e-07, 8.2732e+20],\n",
      "        [1.6689e-07, 1.3167e-08],\n",
      "        [1.6918e-04, 2.1630e+23]])\n",
      "tensor([1, 0, 2]) torch.LongTensor\n",
      "tensor([[1.6411e-07, 8.2732e+20],\n",
      "        [0.0000e+00, 4.5916e-41],\n",
      "        [1.6689e-07, 1.3167e-08]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# torch中没有random.shuffle\n",
    "# y = torch.randperm(n) y是把0到n-1这些数随机打乱得到的一个数字序列\n",
    "# randperm(n, out=None, dtype=torch.int64)-> LongTensor\n",
    "idx = torch.randperm(3)\n",
    "a = torch.Tensor(4, 2)\n",
    "print(a)\n",
    "print(idx, idx.type())\n",
    "print(a[idx])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 六、张量的索引与切片"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.1 索引"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a[0].shape: torch.Size([3, 28, 28])\n",
      "a[0,0].shape: torch.Size([28, 28])\n",
      "a[0,0,2,4]: tensor(0.4791)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(4, 3, 28, 28)\n",
    "print(\"a[0].shape:\", a[0].shape)\n",
    "print(\"a[0,0].shape:\", a[0, 0].shape)\n",
    "print(\"a[0,0,2,4]:\", a[0, 0, 2, 4])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.2 切片"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.2.1 获取张量的前/后N个元素"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.shape: torch.Size([4, 3, 28, 28])\n",
      "a[:2].shape: torch.Size([2, 3, 28, 28])\n",
      "a[:2,:1,:,:].shape: torch.Size([2, 1, 28, 28])\n",
      "a[:2,1:,:,:].shape: torch.Size([2, 2, 28, 28])\n",
      "a[:2,-1:,:,:].shape: torch.Size([2, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(4, 3, 28, 28)\n",
    "print(\"a.shape:\", a.shape)\n",
    "\n",
    "print(\"a[:2].shape:\", a[:2].shape)\n",
    "print(\"a[:2,:1,:,:].shape:\", a[:2, :1, :, :].shape)\n",
    "print(\"a[:2,1:,:,:].shape:\", a[:2, 1:, :, :].shape)\n",
    "print(\"a[:2,-1:,:,:].shape:\", a[:2, -1:, :, :].shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.2.2 根据指定步长获取张量的前/后N个元素"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.shape: torch.Size([4, 3, 28, 28])\n",
      "a[:,:,0:28:2,0:28:2].shape: torch.Size([4, 3, 14, 14])\n",
      "a[:,:,::2,::2].shape: torch.Size([4, 3, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(4, 3, 28, 28)\n",
    "print(\"a.shape:\", a.shape)\n",
    "\n",
    "print(\"a[:,:,0:28:2,0:28:2].shape:\", a[:, :, 0:28:2, 0:28:2].shape)\n",
    "print(\"a[:,:,::2,::2].shape:\", a[:, :, ::2, ::2].shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.2.3 根据特殊索引获取张量值"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.shape: torch.Size([4, 3, 28, 28])\n",
      "a.index_select(0,torch.tensor([0,2])).shape: torch.Size([2, 3, 28, 28])\n",
      "a.index_select(1,torch.tensor([1,2])).shape: torch.Size([4, 2, 28, 28])\n",
      "a.index_select(2,torch.arange(28)).shape: torch.Size([4, 3, 28, 28])\n",
      "a.index_select(2,torch.arange(8)).shape: torch.Size([4, 3, 8, 28])\n",
      "a[...].shape: torch.Size([4, 3, 28, 28])\n",
      "a[0,...].shape: torch.Size([3, 28, 28])\n",
      "a[:,1,...].shape: torch.Size([4, 28, 28])\n",
      "a[...,:2].shape: torch.Size([4, 3, 28, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(4, 3, 28, 28)\n",
    "print(\"a.shape:\", a.shape)\n",
    "\n",
    "print(\"a.index_select(0,torch.tensor([0,2])).shape:\", a.index_select(0, torch.tensor([0, 2])).shape)\n",
    "print(\"a.index_select(1,torch.tensor([1,2])).shape:\", a.index_select(1, torch.tensor([1, 2])).shape)\n",
    "print(\"a.index_select(2,torch.arange(28)).shape:\", a.index_select(2, torch.arange(28)).shape)\n",
    "print(\"a.index_select(2,torch.arange(8)).shape:\", a.index_select(2, torch.arange(8)).shape)\n",
    "\n",
    "print(\"a[...].shape:\", a[...].shape)\n",
    "print(\"a[0,...].shape:\", a[0, ...].shape)\n",
    "print(\"a[:,1,...].shape:\", a[:, 1, ...].shape)\n",
    "print(\"a[...,:2].shape:\", a[..., :2].shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.2.4 根据 mask 选取张量值"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4041, 0.6005, 0.1984, 0.1672],\n",
      "        [0.1053, 0.8833, 0.1248, 0.9476],\n",
      "        [0.6271, 0.6862, 0.7329, 0.0712]])\n",
      "tensor([[False,  True, False, False],\n",
      "        [False,  True, False,  True],\n",
      "        [ True,  True,  True, False]])\n",
      "tensor([0.6005, 0.8833, 0.9476, 0.6271, 0.6862, 0.7329])\n",
      "torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(3, 4)\n",
    "print(a)\n",
    "\n",
    "mask = a.ge(0.5)\n",
    "print(mask)\n",
    "\n",
    "b = torch.masked_select(a, mask)\n",
    "print(b)\n",
    "print(b.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.2.5 根据展平的索引获取张量值"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 3., 5.],\n",
      "        [6., 7., 8.]])\n",
      "tensor([4., 5., 8.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.Tensor([[4, 3, 5], [6, 7, 8]])\n",
    "print(a)\n",
    "print(torch.take(a, torch.tensor([0, 2, -1])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 七、张量的维度变换"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7.1 view 和 reshape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 28, 28])\n",
      "torch.Size([4, 784])\n",
      "torch.Size([112, 28])\n",
      "torch.Size([4, 28, 28, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(4, 1, 28, 28)\n",
    "print(a.shape)\n",
    "\n",
    "print(a.view(4, 28 * 28).shape)\n",
    "print(a.view(4 * 28, 28).shape)\n",
    "print(a.view(4, 28, 28, 1).shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7.2 unsqueeze 升维"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.shape: torch.Size([4, 1, 28, 28])\n",
      "a.unsqueeze(0).shape: torch.Size([1, 4, 1, 28, 28])\n",
      "a.unsqueeze(-1).shape: torch.Size([4, 1, 28, 28, 1])\n",
      "b.shape: torch.Size([32])\n",
      "b.unsqueeze(1).unsqueeze(2).unsqueeze(0).shape: torch.Size([1, 32, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(4, 1, 28, 28)\n",
    "print(\"a.shape:\", a.shape)\n",
    "\n",
    "print(\"a.unsqueeze(0).shape:\", a.unsqueeze(0).shape)\n",
    "print(\"a.unsqueeze(-1).shape:\", a.unsqueeze(-1).shape)\n",
    "\n",
    "b = torch.rand(32)\n",
    "print(\"b.shape:\", b.shape)\n",
    "print(\"b.unsqueeze(1).unsqueeze(2).unsqueeze(0).shape:\", b.unsqueeze(1).unsqueeze(2).unsqueeze(0).shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7.3 squeeze 降维"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b.shape: torch.Size([4, 1, 28, 28])\n",
      "b.squeeze().shape: torch.Size([4, 28, 28])\n",
      "b.squeeze(0).shape: torch.Size([4, 1, 28, 28])\n",
      "b.squeeze(-1).shape: torch.Size([4, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "b = torch.rand(4, 1, 28, 28)\n",
    "print(\"b.shape:\", b.shape)\n",
    "\n",
    "print(\"b.squeeze().shape:\", b.squeeze().shape)\n",
    "print(\"b.squeeze(0).shape:\", b.squeeze(0).shape)\n",
    "print(\"b.squeeze(-1).shape:\", b.squeeze(-1).shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7.4 expand"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b.shape: torch.Size([1, 32, 1, 1])\n",
      "b.expand(4,32,14,14).shape: torch.Size([4, 32, 14, 14])\n",
      "b.expand(-1,32,-1,-1).shape: torch.Size([1, 32, 1, 1])\n",
      "b.expand(-1,32,-1,4).shape: torch.Size([1, 32, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "b = torch.rand(1, 32, 1, 1)\n",
    "print(\"b.shape:\", b.shape)\n",
    "\n",
    "print(\"b.expand(4,32,14,14).shape:\", b.expand(4, 32, 14, 14).shape)\n",
    "print(\"b.expand(-1,32,-1,-1).shape:\", b.expand(-1, 32, -1, -1).shape)\n",
    "print(\"b.expand(-1,32,-1,4).shape:\", b.expand(-1, 32, -1, 4).shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7.5 repeat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b.shape: torch.Size([1, 32, 1, 1])\n",
      "b.repeat(4,32,1,1).shape: torch.Size([4, 1024, 1, 1])\n",
      "b.repeat(4,1,1,1).shape: torch.Size([4, 32, 1, 1])\n",
      "b.repeat(4,1,32,32).shape: torch.Size([4, 32, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "b = torch.rand(1, 32, 1, 1)\n",
    "print(\"b.shape:\", b.shape)\n",
    "\n",
    "print(\"b.repeat(4,32,1,1).shape:\", b.repeat(4, 32, 1, 1).shape)\n",
    "print(\"b.repeat(4,1,1,1).shape:\", b.repeat(4, 1, 1, 1).shape)\n",
    "print(\"b.repeat(4,1,32,32).shape:\", b.repeat(4, 1, 32, 32).shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7.6 .t()转置"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0218, 0.0356, 0.9472, 0.4952],\n",
      "        [0.6545, 0.3335, 0.9319, 0.7809],\n",
      "        [0.7616, 0.7047, 0.6538, 0.6556]])\n",
      "tensor([[0.0218, 0.6545, 0.7616],\n",
      "        [0.0356, 0.3335, 0.7047],\n",
      "        [0.9472, 0.9319, 0.6538],\n",
      "        [0.4952, 0.7809, 0.6556]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "b = torch.rand(3, 4)\n",
    "print(b)\n",
    "print(b.t())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7.7 transpose 维度变换"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 28, 28])\n",
      "torch.Size([4, 28, 28, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(4, 3, 28, 28)\n",
    "print(a.shape)\n",
    "print(a.transpose(1, 3).shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7.8 permute 维度变换"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 28, 28])\n",
      "torch.Size([4, 28, 28, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(4, 3, 28, 28)\n",
    "print(a.shape)\n",
    "print(a.permute(0, 2, 3, 1).shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 八、张量的拼接和拆分"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8.1 cat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 32, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(4, 32, 8)\n",
    "b = torch.rand(5, 32, 8)\n",
    "c = torch.cat([a, b], dim=0)\n",
    "print(c.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8.2 stack"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 2, 16, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a1 = torch.rand(4, 3, 16, 32)\n",
    "a2 = torch.rand(4, 3, 16, 32)\n",
    "c = torch.stack([a1, a2], dim=2)\n",
    "print(c.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8.3 split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 32, 8])\n",
      "torch.Size([1, 32, 8]) torch.Size([1, 32, 8])\n",
      "torch.Size([2, 20, 8]) torch.Size([2, 12, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(32, 8)\n",
    "b = torch.rand(32, 8)\n",
    "c = torch.stack([a, b], dim=0)\n",
    "print(c.shape)  # torch.Size([2, 32, 8])\n",
    "\n",
    "aa, bb = c.split([1, 1], dim=0)\n",
    "print(aa.shape, bb.shape)  # torch.Size([1, 32, 8]) torch.Size([1, 32, 8])\n",
    "\n",
    "aa, bb = c.split([20, 12], dim=1)\n",
    "print(aa.shape, bb.shape)  # torch.Size([2, 20, 8]) torch.Size([2, 12, 8])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8.4 chunk"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 32, 8])\n",
      "torch.Size([1, 32, 8]) torch.Size([1, 32, 8])\n",
      "torch.Size([2, 16, 8]) torch.Size([2, 16, 8])\n",
      "torch.Size([2, 8, 8]) torch.Size([2, 8, 8]) torch.Size([2, 8, 8]) torch.Size([2, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(32, 8)\n",
    "b = torch.rand(32, 8)\n",
    "c = torch.stack([a, b], dim=0)\n",
    "print(c.shape)  # torch.Size([2, 32, 8])\n",
    "\n",
    "aa, bb = c.chunk(2, dim=0)\n",
    "print(aa.shape, bb.shape)  # torch.Size([1, 32, 8]) torch.Size([1, 32, 8])\n",
    "\n",
    "aa, bb = c.chunk(2, dim=1)\n",
    "print(aa.shape, bb.shape)  # torch.Size([2, 16, 8]) torch.Size([2, 16, 8])\n",
    "\n",
    "aa, bb, cc, dd = c.chunk(4, dim=1)\n",
    "print(aa.shape, bb.shape, cc.shape,\n",
    "      dd.shape)  #torch.Size([2, 8, 8]) torch.Size([2, 8, 8]) torch.Size([2, 8, 8]) torch.Size([2, 8, 8])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 九、基本运算"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 9.1 广播机制"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5992, 0.2061],\n",
      "        [0.9040, 0.6210]])\n",
      "tensor([0.8494, 0.9617])\n",
      "tensor([[1.4486, 1.1678],\n",
      "        [1.7535, 1.5827]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(2, 2)\n",
    "print(a)\n",
    "b = torch.rand(2)\n",
    "print(b)\n",
    "print(a + b)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 9.2 matmul 矩阵/张量乘法"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[6., 6.],\n",
      "        [6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.ones(2, 2) * 3\n",
    "b = torch.ones(2, 2)\n",
    "print(a)\n",
    "print(b)\n",
    "print(torch.matmul(a, b))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 9.3 次方运算"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "tensor([[27., 27.],\n",
      "        [27., 27.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.ones(2, 2) * 3\n",
    "print(a)\n",
    "print(torch.pow(a, 3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 9.4 sqrt 平方根运算"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9., 9.],\n",
      "        [9., 9.]])\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.ones(2, 2) * 9\n",
    "print(a)\n",
    "print(torch.pow(a, 0.5))\n",
    "print(torch.sqrt(a))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 9.5 exp 指数幂运算"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[2.7183, 2.7183],\n",
      "        [2.7183, 2.7183]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.ones(2, 2)\n",
    "print(a)\n",
    "print(torch.exp(a))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 9.6 log 对数运算"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "tensor([[1.0986, 1.0986],\n",
      "        [1.0986, 1.0986]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.ones(2, 2) * 3\n",
    "print(a)\n",
    "print(torch.log(a))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 9.7 取整"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1400)\n",
      "tensor(3.)\n",
      "tensor(4.)\n",
      "tensor(3.)\n",
      "tensor(3.)\n",
      "tensor(0.1400)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor(3.14)\n",
    "print(a)  # tensor(3.1400)\n",
    "print(torch.floor(a))  #tensor(3.)\n",
    "print(torch.ceil(a))  #tensor(4.)\n",
    "print(torch.round(a))  #tensor(3.)\n",
    "print(torch.trunc(a))  #tensor(3.)\n",
    "print(torch.frac(a))  #tensor(0.1400)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 9.8 clamp 控制张量的取值范围"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8.8872,  5.6534, 14.3027],\n",
      "        [ 0.8305, 12.6266, 13.9683]])\n",
      "tensor([[8.0000, 5.6534, 8.0000],\n",
      "        [4.0000, 8.0000, 8.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(2, 3) * 15\n",
    "\n",
    "print(a)\n",
    "# 将大于8的值设置为8；小于4的值设置为4\n",
    "print(torch.clamp(a, 4, 8))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 十、统计属性"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 10.1 norm 求范数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor(2.4495)\n",
      "tensor(6.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.ones(2, 3)\n",
    "b = torch.norm(a)  # 默认求2范数\n",
    "c = torch.norm(a, p=1)  # 指定求1范数\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 10.2 mean、median、sum、min、max、prod、argmax、argmin"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2., 3.],\n",
      "        [4., 5., 6., 7.]])\n",
      "tensor(3.5000)\n",
      "tensor(3.)\n",
      "tensor(28.)\n",
      "tensor(0.)\n",
      "tensor(7.)\n",
      "tensor(0.)\n",
      "tensor(7)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.arange(8).view(2, 4).float()\n",
    "print(a)\n",
    "'''\n",
    "tensor([[0., 1., 2., 3.],\n",
    "        [4., 5., 6., 7.]])\n",
    "'''\n",
    "print(a.mean())  #tensor(3.5000)\n",
    "print(a.median())  #tensor(3.)\n",
    "print(a.sum())  #tensor(28.)\n",
    "print(a.min())  #tensor(0.)\n",
    "print(a.max())  #tensor(7.)\n",
    "print(a.prod())  #tensor(0.)\n",
    "print(a.argmax())  #tensor(7)\n",
    "print(a.argmin())  #tensor(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7239, 0.9412, 0.7602, 0.2131],\n",
      "        [0.6277, 0.1033, 0.8300, 0.9909]])\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9412, 0.9909]),\n",
      "indices=tensor([1, 3]))\n",
      "torch.return_types.max(\n",
      "values=tensor([[0.9412],\n",
      "        [0.9909]]),\n",
      "indices=tensor([[1],\n",
      "        [3]]))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(2, 4)\n",
    "print(a)\n",
    "\n",
    "print(a.max(dim=1))\n",
    "print(a.max(dim=1, keepdim=True))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 10.3 topk"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3247, 0.9220, 0.4314, 0.8123],\n",
      "        [0.7133, 0.2471, 0.0281, 0.3595]])\n",
      "torch.return_types.topk(\n",
      "values=tensor([[0.9220, 0.8123],\n",
      "        [0.7133, 0.3595]]),\n",
      "indices=tensor([[1, 3],\n",
      "        [0, 3]]))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(2, 4)\n",
    "print(a)\n",
    "print(a.topk(2, dim=1))\n",
    "'''\n",
    "tensor([[0.3247, 0.9220, 0.4314, 0.8123],\n",
    "        [0.7133, 0.2471, 0.0281, 0.3595]])\n",
    "torch.return_types.topk(\n",
    "values=tensor([[0.9220, 0.8123],\n",
    "        [0.7133, 0.3595]]),\n",
    "indices=tensor([[1, 3],\n",
    "        [0, 3]]))\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 10.4 kthvalue"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0980, 0.0479, 0.9298, 0.5638],\n",
      "        [0.9095, 0.9071, 0.4913, 0.6144]])\n",
      "torch.return_types.kthvalue(\n",
      "values=tensor([0.5638, 0.9071]),\n",
      "indices=tensor([3, 1]))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(2, 4)\n",
    "print(a)\n",
    "print(a.kthvalue(3, dim=1))\n",
    "'''\n",
    "tensor([[0.0980, 0.0479, 0.9298, 0.5638],\n",
    "        [0.9095, 0.9071, 0.4913, 0.6144]])\n",
    "torch.return_types.kthvalue(\n",
    "values=tensor([0.5638, 0.9071]),\n",
    "indices=tensor([3, 1]))\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 10.5 比较运算函数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1196, 0.5068, 0.9272],\n",
      "        [0.6395, 0.2433, 0.9702]])\n",
      "tensor([[False,  True,  True],\n",
      "        [ True, False,  True]])\n",
      "tensor([[False,  True,  True],\n",
      "        [ True, False,  True]])\n",
      "tensor([[ True, False, False],\n",
      "        [False,  True, False]])\n",
      "tensor([[ True, False, False],\n",
      "        [False,  True, False]])\n",
      "tensor([[False, False, False],\n",
      "        [False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(2, 3)\n",
    "print(a)\n",
    "'''\n",
    "tensor([[0.1196, 0.5068, 0.9272],\n",
    "        [0.6395, 0.2433, 0.9702]])\n",
    "'''\n",
    "# a >= 0.5\n",
    "print(a.ge(0.5))\n",
    "'''\n",
    "tensor([[False,  True,  True],\n",
    "        [ True, False,  True]])\n",
    "'''\n",
    "# a > 0.5\n",
    "print(a.gt(0.5))\n",
    "'''\n",
    "tensor([[False,  True,  True],\n",
    "        [ True, False,  True]])\n",
    "'''\n",
    "# a <= 0.5\n",
    "print(a.le(0.5))\n",
    "'''\n",
    "tensor([[ True, False, False],\n",
    "        [False,  True, False]])\n",
    "'''\n",
    "# a < 0.5\n",
    "print(a.lt(0.5))\n",
    "'''\n",
    "tensor([[ True, False, False],\n",
    "        [False,  True, False]])\n",
    "'''\n",
    "# a = 0.5\n",
    "print(a.eq(0.5))\n",
    "'''\n",
    "tensor([[False, False, False],\n",
    "        [False, False, False]])\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 十一、高级操作"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 11.1 where"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3622, 0.9658],\n",
      "        [0.1774, 0.6670]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "cond = torch.rand(2, 2)\n",
    "a = torch.zeros(2, 2)\n",
    "b = torch.ones(2, 2)\n",
    "print(cond)\n",
    "'''\n",
    "tensor([[0.3622, 0.9658],\n",
    "        [0.1774, 0.6670]])\n",
    "'''\n",
    "print(a)\n",
    "'''\n",
    "tensor([[0., 0.],\n",
    "        [0., 0.]])\n",
    "'''\n",
    "print(b)\n",
    "'''\n",
    "tensor([[1., 1.],\n",
    "        [1., 1.]])\n",
    "'''\n",
    "# 满足条件cond.ge(0.5)的按照a的对应元素赋值，否则按照b的对应元素赋值\n",
    "print(torch.where(cond.ge(0.5), a, b))\n",
    "'''\n",
    "tensor([[1., 0.],\n",
    "        [1., 0.]])\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 11.2 gather"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n",
      "tensor([[5, 4, 3]])\n",
      "tensor([[5],\n",
      "        [7],\n",
      "        [9]])\n",
      "tensor([[3, 5],\n",
      "        [7, 8]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.arange(3, 12).view(3, 3)\n",
    "print(a)\n",
    "'''\n",
    "tensor([[ 3,  4,  5],\n",
    "        [ 6,  7,  8],\n",
    "        [ 9, 10, 11]])\n",
    "'''\n",
    "\n",
    "index = torch.tensor([[2, 1, 0]])\n",
    "print(a.gather(1, index)) # tensor([[5, 4, 3]])\n",
    "\n",
    "index = torch.tensor([[2, 1, 0]]).t()\n",
    "print(a.gather(1, index))\n",
    "'''\n",
    "tensor([[5],\n",
    "        [7],\n",
    "        [9]])\n",
    "'''\n",
    "\n",
    "index = torch.tensor([[0, 2],\n",
    "                      [1, 2]])\n",
    "print(a.gather(1, index))\n",
    "'''\n",
    "tensor([[3, 5],\n",
    "        [7, 8]])\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
